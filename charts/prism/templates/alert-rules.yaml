# Copyright (c) Ultraviolet
# SPDX-License-Identifier: Apache-2.0

apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: {{ .Release.Name }}-alerts
  namespace: {{ .Release.Namespace }}
  labels:
    release: {{ .Release.Name }}
spec:
  groups:
    - name: prism.high-error-rate
      rules:
        - alert: HighErrorRate
          expr: |
            (
              sum(rate(http_requests_total{job="prism", component=~"(auth|backends|billing|certs|computations|cvm-billing|domains|ui|users|spicedb|am-certs)", status_code=~"5.."}[5m])) by (component)
              /
              sum(rate(http_requests_total{job="prism", component=~"(auth|backends|billing|certs|computations|cvm-billing|domains|ui|users|spicedb|am-certs)"}[5m])) by (component)
            ) * 100 > 5
          for: 5m
          labels: { severity: warning, service: "{{ `{{ $labels.component }}` }}" }
          annotations:
            summary: "High error rate detected for {{ `{{ $labels.component }}` }}"
            description: >
              Service {{ `{{ $labels.component }}` }} has error rate of  {{ `{{ printf "%.2f" $value }}` }}%
              for more than 5 minutes

        - alert: CriticalErrorRate
          expr: |
            (
              sum(rate(http_requests_total{job="prism", component=~"(auth|backends|billing|certs|computations|cvm-billing|domains|ui|users|spicedb|am-certs)", status_code=~"5.."}[5m])) by (component)
              /
              sum(rate(http_requests_total{job="prism", component=~"(auth|backends|billing|certs|computations|cvm-billing|domains|ui|users|spicedb|am-certs)"}[5m])) by (component)
            ) * 100 > 20
          for: 2m
          labels: { severity: critical, service: "{{ `{{ $labels.component }}` }}" }
          annotations:
            summary: "Critical error rate detected for  {{ `{{ $labels.component }}` }}"
            description: >
              Service {{ `{{ $labels.component }}` }} has critical error rate of  {{ `{{ printf "%.2f" $value }}` }}%
              for more than 2 minutes

    - name: prism.service-availability
      rules:
        - alert: ServiceDown
          expr: up{job="prism", component=~"(auth|backends|billing|certs|computations|domains|ui|users|traefik|am-certs)"} == 0
          for: 1m
          labels: { severity: critical, service: "{{ `{{ $labels.component }}` }}" }
          annotations:
            summary: "Service {{ `{{ $labels.component }}` }} is down"
            description: >
              Service {{ `{{ $labels.component }}` }} has been down for more than 1 minute

        - alert: ServiceUnhealthy
          expr: |
            (
              sum(up{job="prism", component=~"(auth|backends|billing|certs|computations|domains|ui|users|traefik|am-certs)"}) by (component)
              /
              count(up{job="prism", component=~"(auth|backends|billing|certs|computations|domains|ui|users|traefik|am-certs)"}) by (component)
            ) * 100 < 75
          for: 5m
          labels: { severity: warning, service: "{{ `{{ $labels.component }}` }}" }
          annotations:
            summary: "Service {{ `{{ $labels.component }}` }} is unhealthy"
            description: >
              Less than 75% of {{ `{{ $labels.component }}` }} instances are healthy
              for more than 5 minutes

    - name: prism.resource-utilization
      rules:
        - alert: HighCPUUsage
          expr: |
            (
              sum(rate(container_cpu_usage_seconds_total{pod=~"prism-staging-(auth|backends|billing|certs|computations|cvm-billing|domains|ui|users|spicedb|traefik|am-certs)-.*"}[5m])) by (pod)
              /
              sum(container_spec_cpu_quota{pod=~"prism-staging-(auth|backends|billing|certs|computations|cvm-billing|domains|ui|users|spicedb|traefik|am-certs)-.*"} / container_spec_cpu_period{pod=~"prism-staging-(auth|backends|billing|certs|computations|cvm-billing|domains|ui|users|spicedb|traefik|am-certs)-.*"}) by (pod)
            ) * 100 > 80
          for: 5m
          labels: { severity: warning, service:  "{{ `{{ $labels.pod }}` }}" }
          annotations:
            summary: "High CPU usage for  {{ `{{ $labels.pod }}` }} "
            description: >
              Pod {{ `{{ $labels.pod }}` }} is using  {{ `{{ printf "%.2f" $value }}` }}% CPU
              for more than 5 minutes

        - alert: HighMemoryUsage
          expr: |
            (
              sum(container_memory_working_set_bytes{pod=~"prism-staging-(auth|backends|billing|certs|computations|cvm-billing|domains|ui|users|spicedb|traefik|am-certs)-.*"}) by (pod)
              /
              sum(container_spec_memory_limit_bytes{pod=~"prism-staging-(auth|backends|billing|certs|computations|cvm-billing|domains|ui|users|spicedb|traefik|am-certs)-.*"}) by (pod)
            ) * 100 > 85
          for: 5m
          labels: { severity: warning, service:  "{{ `{{ $labels.pod }}` }}" }
          annotations:
            summary: "High memory usage for  {{ `{{ $labels.pod }}` }} "
            description: >
              Pod {{ `{{ $labels.pod }}` }} is using  {{ `{{ printf "%.2f" $value }}` }}% memory
              for more than 5 minutes

        - alert: PodRestartingFrequently
          expr: increase(kube_pod_container_status_restarts_total{pod=~"prism-staging-(auth|backends|billing|certs|computations|cvm-billing|domains|ui|users|spicedb|traefik|am-certs)-.*"}[1h]) > 3
          for: 1m
          labels: { severity: warning, service:  "{{ `{{ $labels.pod }}` }}" }
          annotations:
            summary: "Pod {{ `{{ $labels.pod }}` }} restarting frequently"
            description: >
              Pod {{ `{{ $labels.pod }}` }} has restarted {{ `{{ $value }}` }} times
              in the last hour

    - name: prism.response-time
      rules:
        - alert: HighResponseTime
          expr: |
            histogram_quantile(0.95,
              sum(rate(http_request_duration_seconds_bucket{job="prism", component=~"(auth|backends|billing|certs|computations|cvm-billing|domains|ui|users|spicedb|am-certs)"}[5m])) by (component, le)
            ) > 2
          for: 5m
          labels: { severity: warning, service: "{{ `{{ $labels.component }}` }}" }
          annotations:
            summary: "High response time for  {{ `{{ $labels.component }}` }}"
            description: >
              95th percentile response time for {{ `{{ $labels.component }}` }} is  {{ `{{ printf "%.2f" $value }}` }}s
              for more than 5 minutes

        - alert: VeryHighResponseTime
          expr: |
            histogram_quantile(0.95,
              sum(rate(http_request_duration_seconds_bucket{job="prism", component=~"(auth|backends|billing|certs|computations|cvm-billing|domains|ui|users|spicedb|am-certs)"}[5m])) by (component, le)
            ) > 5
          for: 2m
          labels: { severity: critical, service: "{{ `{{ $labels.component }}` }}" }
          annotations:
            summary: "Very high response time for  {{ `{{ $labels.component }}` }}"
            description: >
              95th percentile response time for {{ `{{ $labels.component }}` }} is  {{ `{{ printf "%.2f" $value }}` }}s
              for more than 2 minutes



    - name: prism.traefik-alerts
      rules:
        - alert: TraefikHighRequestRate
          expr: |
            sum(rate(traefik_service_requests_total[5m])) by (service) > 1000
          for: 5m
          labels: { severity: warning, service: traefik }
          annotations:
            summary: "High request rate through Traefik"
            description: >
              Traefik service {{ `{{ $labels.service }}` }} is handling {{ `{{ printf "%.0f" $value }}` }}
              requests/sec

        - alert: TraefikServiceUnavailable
          expr: |
            sum(rate(traefik_service_requests_total{code=~"5.."}[5m])) by (service) / sum(rate(traefik_service_requests_total[5m])) by (service) > 0.05
          for: 5m
          labels: { severity: critical, service: traefik }
          annotations:
            summary: "Service unavailable through Traefik"
            description: >
              Traefik service {{ `{{ $labels.service }}` }} has {{ `{{ printf "%.2f" $value | humanizePercentage }}` }}
              error rate

    - name: cocos-manager-alerts-tdx
      rules:
        - alert: CocosManagerDown
          expr: up{job="cocos-manager-tdx"} == 0
          for: 1m
          labels:
            severity: critical
            service: cocos-manager
          annotations:
            summary: "Cocos Manager service is down"
            description: "Cocos Manager service has been down for more than 1 minute. Instance: {{ `{{ $labels.instance }}` }}"

        - alert: CocosManagerNoMetrics
          expr: absent(up{job="cocos-manager-tdx"})
          for: 2m
          labels:
            severity: critical
            service: cocos-manager
          annotations:
            summary: "No metrics received from Cocos Manager"
            description: "No metrics have been received from Cocos Manager for more than 2 minutes"

        - alert: CocosManagerUnhealthy
          expr: health_check{job="cocos-manager-tdx"} == 0
          for: 30s
          labels:
            severity: warning
            service: cocos-manager
          annotations:
            summary: "Cocos Manager health check failing"
            description: "Cocos Manager health check has been failing for more than 30 seconds. Instance: {{ `{{ $labels.instance }}` }}"

        - alert: CocosManagerHighLatency
          expr: histogram_quantile(0.95, rate(cocos_manager_latency_bucket[5m])) > 2
          for: 5m
          labels:
            severity: warning
            service: cocos-manager
          annotations:
            summary: "Cocos Manager high latency"
            description: "Cocos Manager 95th percentile latency is above 2 seconds for more than 5 minutes. Current value: {{ `{{ $value }}` }}s"

        - alert: CocosManagerHighErrorRate
          expr: rate(cocos_manager_errors_total[5m]) > 0.1
          for: 2m
          labels:
            severity: warning
            service: cocos-manager
          annotations:
            summary: "Cocos Manager high error rate"
            description: "Cocos Manager error rate is above 10% for more than 2 minutes. Current rate: {{ `{{ $value }}` }}"

    - name: cocos-manager-alerts-snp
      rules:
        - alert: CocosManagerDown
          expr: up{job="cocos-manager-snp"} == 0
          for: 1m
          labels:
            severity: critical
            service: cocos-manager
          annotations:
            summary: "Cocos Manager service is down"
            description: "Cocos Manager service has been down for more than 1 minute. Instance: {{ `{{ $labels.instance }}` }}"

        - alert: CocosManagerNoMetrics
          expr: absent(up{job="cocos-manager-snp"})
          for: 2m
          labels:
            severity: critical
            service: cocos-manager
          annotations:
            summary: "No metrics received from Cocos Manager"
            description: "No metrics have been received from Cocos Manager for more than 2 minutes"

        - alert: CocosManagerUnhealthy
          expr: health_check{job="cocos-manager-snp"} == 0
          for: 30s
          labels:
            severity: warning
            service: cocos-manager
          annotations:
            summary: "Cocos Manager health check failing"
            description: "Cocos Manager health check has been failing for more than 30 seconds. Instance: {{ `{{ $labels.instance }}` }}"

        - alert: CocosManagerHighLatency
          expr: histogram_quantile(0.95, rate(cocos_manager_latency_bucket[5m])) > 2
          for: 5m
          labels:
            severity: warning
            service: cocos-manager
          annotations:
            summary: "Cocos Manager high latency"
            description: "Cocos Manager 95th percentile latency is above 2 seconds for more than 5 minutes. Current value: {{ `{{ $value }}` }}s"

        - alert: CocosManagerHighErrorRate
          expr: rate(cocos_manager_errors_total[5m]) > 0.1
          for: 2m
          labels:
            severity: warning
            service: cocos-manager
          annotations:
            summary: "Cocos Manager high error rate"
            description: "Cocos Manager error rate is above 10% for more than 2 minutes. Current rate: {{ `{{ $value }}` }}"
